{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import datetime as dt\n",
    "import statistics\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option(\"max_columns\", None)\n",
    "pd.options.display.float_format = '{:,.10f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the available databases for Boston.\n",
    "Despite that there is more recent information available in inside Airbnb, our analysis uses the data extraction from 13 February in order to avoid data after the massive spread of COVID 19 thoughout USA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/rwester/Documents/Ricardo W/Apuntes,Cursos,Estudios/Data Science Nanodegree programm/Boston/'\n",
    "listings=pd.read_csv(path+'listings.csv')\n",
    "calendar=pd.read_csv(path+'calendar.csv')\n",
    "reviews=pd.read_csv(path+'reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting are the offered price and availability by date for every listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.info()\n",
    "calendar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Calendar shows the availability for the next 365 days with their respective price.\n",
    "The price by date could be usefull to determine the price variations and their amount during the year.\n",
    "There is information about 3903 listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calendar.date.min(),calendar.date.max())\n",
    "print(calendar.listing_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean availability (due to other guest reservation or block of the day by the host) are less than half for the next 365 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar['available'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The listings database seems to be very rich in information. \n",
    "Neighborhood, GPS location, score and amenities description are available for every listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.info()\n",
    "listings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviews by guests for every listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.info()\n",
    "print(reviews.head())\n",
    "print(reviews['date'].min())\n",
    "print(reviews['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on the available data seeing above, we ask ourself the following questions: \n",
    "\n",
    "* a)Which are the most demanded seasons in boston?\n",
    "* b)How much rise prices during high season?\n",
    "* c)Which are the most expensive neighbourhoods?\n",
    "* d)Which are the most demanded neighbourhoods?\n",
    "\n",
    "For answering these questions we will use data from the calendar, reviews and listings databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which are the most demanded seasons in boston?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the first question, we need to estimate the occupancy by date.\n",
    "\n",
    "The Calendar information may not be useful cause the reason behind an unavailable date is not public available, \n",
    "(it's imposible to distinguish wheter it's already booked by other guest or the date is block by the host).\n",
    "\n",
    "Instead, the assumption of the occupancy model from the \"Inside Airbnb San Francisco Model\" will be used. \n",
    "\n",
    "The assumption states that 50% of the total listing's bookings write a review \n",
    "(source: http://insideairbnb.com/about.html#disclaimers).\n",
    "\n",
    "We plot the bookings by date and highlight the dates of the boston marathon from the last 3 years, event that gathers more than\n",
    "30.000 competitors by year and that with certainty causes a peak of demand that day. (source: https://www.baa.org/races/boston-marathon/results/participation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_new = reviews.copy()\n",
    "\n",
    "review_new = review_new.groupby('date')['id'].unique().reset_index()\n",
    "review_new['id']=review_new['id'].map(lambda x: 2*len(x))\n",
    "review_new['date'] = pd.to_datetime(review_new['date'])\n",
    "\n",
    "d1=dt.datetime(2017,1,1)\n",
    "bm17=dt.datetime(2017,4,17)\n",
    "bm18=dt.datetime(2018,4,16)\n",
    "bm19=dt.datetime(2019,4,15)\n",
    "\n",
    "nye17=dt.datetime(2016,12,31)\n",
    "nye18=dt.datetime(2017,12,31)\n",
    "nye19=dt.datetime(2018,12,31)\n",
    "nye20=dt.datetime(2019,12,31)\n",
    "\n",
    "review_new=review_new[review_new['date']>=d1]\n",
    "\n",
    "events={'event':['bm17','bm18','bm19','nye17','nye18','nye19','nye20']\n",
    "        ,'date':[bm17,bm18,bm19,nye17,nye18,nye19,nye20]\n",
    "        ,'color':['red','red','red','green','green','green','green']\n",
    "        }\n",
    "\n",
    "events_df=pd.DataFrame(events)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(review_new['date'], review_new['id'])\n",
    "\n",
    "for i in range(0,events_df.shape[0]):\n",
    "    plt.axvline(x=events_df.iloc[i,1],c=events_df.iloc[i,2],ls=':')\n",
    "\n",
    "plt.title('Boston estimated occupancy by day')\n",
    "plt.ylabel('n° of estimated reservations')\n",
    "plt.savefig('boston_estimated_occupancy.png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that there is a local maximum of demand near the date of the marathon.\n",
    "However, it must be considered that the date of the review is not necesary the date of the stay in the listing place.\n",
    "\n",
    "If we see in detail the estimated reservation by day one week before and after the boston marathon, it can be estimate an average delay between the start day of occupancy and the review. \n",
    "\n",
    "In the following plots the boston marathon date is resalted in red. With a high certainty it can be assume that the observed \n",
    "peak of bookigns actually occurred the day before the competition (competitors need to arrive at least one day before the \n",
    "marathon ir order to be properly restful before the competition), so we can conclude that users write a review on average two \n",
    "days after their stay. This aproximation will be use forward for determine the most demanded day in the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm_subplot(data,events):\n",
    "    '''\n",
    "    Function that display subplots with the estimated bookings by day considering a -/+ 1 week interval near the boston marathon dates\n",
    "    dates from the last 3 years.\n",
    "    Input: data: dataframe with the estimated bookings\n",
    "           events: dataframe with last 3 marathon version's dates\n",
    "    Output: display 3 subplots\n",
    "    '''\n",
    "    dw=dt.timedelta(days=7)\n",
    "    \n",
    "    plt.figure(figsize=(15,5))\n",
    "    \n",
    "    for i in range(0,3):\n",
    "        #marathon date from the last 3 years\n",
    "        md=events.iloc[i,1]\n",
    "        #marathon date interval -/+ 1 week\n",
    "        mi=data[(data['date']>=(md-dw)) & (data['date']<(md+dw))]\n",
    "        \n",
    "        plt.subplot(2,2,i+1)\n",
    "        plt.plot(mi['date'], mi['id'])\n",
    "        plt.axvline(x=md,c='red',ls='-.')\n",
    "        plt.title('Estimated bookings by day near '+str(2017+i)+' BM')\n",
    "        plt.ylabel('n° listings occupancy')\n",
    "        plt.xticks([])\n",
    "        plt.grid(True)\n",
    "        \n",
    "    return plt.show()\n",
    "\n",
    "bm_subplot(review_new,events_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we estimated the average delay we analize the occupancy by month. \n",
    "\n",
    "It is quite obvious that the demand is higher during the warmer months during Spring and Summer, but the question is:\n",
    "how much rise demand during that period?\n",
    "\n",
    "By plotting the estimated demand by month from the previous 3 years, it can be seen that months between May and October\n",
    "are the most demanded. After October the demands falls through Autumm achieving its lower value during the \n",
    "hardest part of winter (January and February)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_new.index = review_new['date']\n",
    "review_monthly=review_new.resample('M').sum()\n",
    "\n",
    "def rw_barplot(size,data,plot_var,title,ylabel,savefig_name):\n",
    "\n",
    "    plt.figure(figsize=(size[0], size[1]))\n",
    "    x_ticks=pd.DataFrame(data=data.index)\n",
    "    x_ticks['date']=x_ticks['date'].dt.strftime(\"%b %Y\")\n",
    "    x_pos = np.arange(len(x_ticks))\n",
    "\n",
    "    plt.bar(x_pos, data[plot_var],align='center')\n",
    "    plt.xticks(x_pos, x_ticks['date'],rotation=90)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.savefig(savefig_name)\n",
    "    return plt.show()\n",
    "\n",
    "              \n",
    "rw_barplot([15,5],review_monthly,'id','Monthly estimated occupancy','n° of estimated reservations','boston_monthly_occupancy.png')             \n",
    "              \n",
    "              \n",
    "review_monthly['month_name']=review_monthly.index.strftime(\"%b\")\n",
    "high_season=['May','Jun','Jul','Aug','Sep','Oct']\n",
    "low_season=['Nov','Dec','Jan','Feb','Mar','Apr']\n",
    "lowest_season=['Jan','Feb']\n",
    "\n",
    "seasons=[high_season,low_season,lowest_season]\n",
    "col_name=['high_season_demand','low_season_demand','lowest_season_demand']\n",
    "\n",
    "#we exclude partially data from february 2020\n",
    "review_monthly=review_monthly.iloc[0:-1,:]\n",
    "\n",
    "def seasons_statistics(data,seasons,col_mame):\n",
    "    '''\n",
    "    Function that estimates the average value of target variable in data for the months specified in the lists inside seasons.\n",
    "    Input: data: dataframe with monthly records for the target variable.\n",
    "           seasons: different list of months that defines partitions of the year.\n",
    "           col_name: name of the output columns\n",
    "    Output: 2 column dataframe with the season or partition of year name and mean value for the target variable.\n",
    "    '''\n",
    "    stats=[]\n",
    "    \n",
    "    for j in range(0,len(seasons)):\n",
    "        season_data=[data.iloc[i][0] for i in range(data.shape[0]) if data.iloc[i][1] in seasons[j]]\n",
    "        stats.append(statistics.mean(season_data))\n",
    "    \n",
    "    dic_aux={'period':col_name,\n",
    "          'mean_value':stats}\n",
    "    output=pd.DataFrame(dic_aux)\n",
    "    return output\n",
    "\n",
    "sd=seasons_statistics(review_monthly,seasons,col_name)\n",
    "\n",
    "def summary_statement(sdf):\n",
    "    avg_high=sdf.iloc[0,1]\n",
    "    avg_low=sdf.iloc[1,1]\n",
    "    avg_lowest=sdf.iloc[2,1]\n",
    "    aux1=\"Average monthly reservations during high season are: \" + str(avg_high) +\".\\n\"\n",
    "    aux2=\"Average monthly reservations during low season are: \" + str(avg_low)+ \" and demand decreases \"\n",
    "    aux3=str((avg_low-avg_high)/avg_high)+ \" vs high season.\\n\"+\"Average monthly reservations during January and February are: \"\n",
    "    aux4=str(avg_lowest)+\" and demand decreases \"+str((avg_lowest-avg_high)/avg_high)+ \" vs high season.\"\n",
    "    return aux1+aux2+aux3+aux4\n",
    "\n",
    "\n",
    "print(summary_statement(sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much rise prices during high season?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_monetary_float(columns,df):\n",
    "    '''\n",
    "    Function that cast columns with monetary data from a string type to float\n",
    "    Input: columns: column list with columns names to be cast\n",
    "           df: dataframe with target columns\n",
    "    Output: dataframe with transform columns\n",
    "    '''\n",
    "    for col in columns:\n",
    "        try:\n",
    "            df[col]=df[col].str.replace(',', '')\n",
    "            df[col]=df[col].str.replace('$', '')\n",
    "            df[col]=df[col].astype(float)\n",
    "        except:\n",
    "            print('Formato incorrecto')\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing from calendar database: monetary columns are transform to float.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar=cast_monetary_float(['price','adjusted_price'],calendar)\n",
    "calendar_new=calendar.copy()\n",
    "\n",
    "calendar_new['date'] = pd.to_datetime(calendar_new['date'])\n",
    "calendar_new=calendar_new[['date','price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price information correspond to the one available in the published calendar of every listing, therefore these prices may be \n",
    "subject to future changes, but still work for identifying price tendencies.\n",
    "\n",
    "Monthly average prices show us that the most demanded months are also the expensivest ones.\n",
    "\n",
    "The average price of the most require months(May-Oct) is 21% higher than \n",
    "the average of the lowest demanded (Nov-Apr) and if we compare the lowest and highest months average (Feb-20 and May-20) the \n",
    "difference is from $85,8 (52pp) , that's a tremendous increase in just 3 months!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar_new.index = calendar_new['date']\n",
    "monthly_prices=calendar_new.resample('M').mean()\n",
    "\n",
    "rw_barplot([15,7],monthly_prices,'price','Monthly listed prices','average price','boston_monthly_listed_prices.png')             \n",
    "              \n",
    "monthly_prices['month_name']=monthly_prices.index.strftime(\"%b\")\n",
    "columns=['high_season_price','low_season_price','lowest_season_price']\n",
    "\n",
    "sp=seasons_statistics(monthly_prices,seasons,col_name)\n",
    "\n",
    "avg_high=sp.iloc[0,1]\n",
    "avg_low=sp.iloc[1,1]\n",
    "avg_lowest=sp.iloc[2,1]\n",
    "\n",
    "print('Average listing price during high season are:', avg_high, '.')\n",
    "print('Average listing price during low season are:', avg_low, 'and high season prices are',(avg_high-avg_low)/avg_low, 'higher')\n",
    "print('Average listing price during January and February are:', avg_lowest, 'and high season prices are',(avg_high-avg_lowest)/avg_lowest, 'higher')\n",
    "\n",
    "greatest_dif=monthly_prices.loc[dt.datetime(2020,5,31)]['price']-monthly_prices.loc[dt.datetime(2020,2,29)]['price']\n",
    "print(greatest_dif)\n",
    "monthly_prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also differences between days of week. Sunday to Tuesday are the cheapest days, from wednesday prices start to \n",
    "rise and continue ascending till Saturday, the expensivest day. Saturday could be on average 5% expensiver than Monday or \n",
    "Tuesday. The price increase logically has a direct relationship with demand rise during weekends. The later can be confirmed\n",
    "with the estimated demand by days of week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "calendar['date'] = pd.to_datetime(calendar['date'])\n",
    "calendar['dayofweek'] = calendar.date.dt.weekday\n",
    "\n",
    "calendar['day_name']=[cats[i] for i in calendar['dayofweek']]\n",
    "price_week=calendar[['day_name','price']]\n",
    "price_week = price_week.groupby(price_week['day_name'])['price'].mean().reindex(cats)\n",
    "\n",
    "def rw_linear_plot(data,label):\n",
    "    data.plot()\n",
    "    ticks = list(range(0, 7, 1))\n",
    "    labels = label.split()\n",
    "    plt.xticks(ticks, labels)\n",
    "    return plt.plot;\n",
    "\n",
    "rw_linear_plot(price_week,\"Mon Tues Weds Thurs Fri Sat Sun\")\n",
    "\n",
    "price_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we apreciate the average number of bookings by day corrected by the estimated delay of two days. It can be seen that \n",
    "weekend's Days are the most demanded headed by Friday, which makes sence cause people that travel for leisure try to take the \n",
    "most of weekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3y=dt.datetime(2017,2,13)\n",
    "\n",
    "review_day = reviews.copy()\n",
    "review_day['date'] = pd.to_datetime(review_day['date'])\n",
    "review_day=review_day[review_day['date']>=l3y]\n",
    "\n",
    "cats = ['Saturday','Sunday','Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "cats_order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "review_day = review_day.groupby('date')['id'].unique().reset_index()\n",
    "review_day['n_reservation']=review_day['id'].map(lambda x: 2*len(x))\n",
    "\n",
    "review_day['dayofweek']=review_day.date.dt.weekday\n",
    "review_day['day_name']=[cats[i] for i in review_day['dayofweek']]\n",
    "\n",
    "occup_week=review_day[['day_name','n_reservation']]\n",
    "\n",
    "occup_week = occup_week.groupby(occup_week['day_name'])['n_reservation'].mean().reindex(cats_order)\n",
    "\n",
    "rw_linear_plot(occup_week,\"Mon Tues Weds Thurs Fri Sat Sun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which are the most expensive neighbourhoods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, proceed to estimate the expensivest neighbourhoods of boston\n",
    "First, we check the listing´s price distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings=cast_monetary_float(['price'],listings)\n",
    "print(listings['price'].describe())\n",
    "\n",
    "#clearly there exists outlyers in the base\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Price distribution')\n",
    "ax1.boxplot(listings['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we inspect the most expensive listings we realize that there are not available (perhaps it was a joke or fake by someone) or\n",
    "the listed price is much lower than the one that appears below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.sort_values(by='price', axis=0, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the main indicators seen above, we have to define a border above which the listings prices will be considered outlyers\n",
    "800 dolars seems to be a plausible limit, because with this criteria only 46 of the 3903 listings will be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=listings.loc[listings.price>800]['price']\n",
    "print(data.count())\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Price distribution')\n",
    "ax1.boxplot(listings.loc[listings.price<=800]['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we obtain average prices by neighbourhood.\n",
    "\n",
    "The South Boston Waterfront and the West end are the expensivest neighbourhoods to book in Airbnb. \n",
    "\n",
    "The first is a district that has suffered a series of renovations since the beginning of the 21st Century that had turn it into a flourish neigbourhood.\n",
    "\n",
    "The second is a mixed-use commercial and residential area district near downtown.\n",
    "\n",
    "After them in prices comes Mission Hill, that is known by his architectural value and then a series of neighbourhoods that are \n",
    "located nearby downtown, like Charlestown, back bay, Beacon hill, North End and Chinatown.\n",
    "\n",
    "The cheapest districts are suburbs located far from downtown, like Mattapan, hyde park and dorchester."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_order = listings.query('price <= 800')\\\n",
    "                    .groupby('neighbourhood_cleansed')['price']\\\n",
    "                    .median()\\\n",
    "                    .sort_values(ascending=False)\\\n",
    "                    .index\n",
    "sns.boxplot(y='price', x='neighbourhood_cleansed', data=listings.query('price <= 800'), \n",
    "            order=sort_order)\n",
    "ax = plt.gca()\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "plt.title('Publish prices distribution by neighbourhood')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which are the most demanded neighbourhoods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer question four we proceed to elaborate a series of indicators \n",
    "\n",
    "The number of reservation per ce don't tell us so much cause bigger neighbourhoods tend to have more listings offer, like \n",
    "Dorchester, East Boston and Roxbury.\n",
    "\n",
    "Therefore we need to look at an indicator at a listing level, like the mean occupancy by listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand_subplots(listings):\n",
    "    '''\n",
    "    Function that display a 2x2 subplot grid with a series of calculated variables at a district level.\n",
    "    Input: listings: dataframe with the listings data\n",
    "    Output: mean prices by neightbourhood and a 2x2 subplot grid\n",
    "    '''\n",
    "    color=['orange','green','red','#1f77b4']\n",
    "    col=['reviews_per_month','id','reviews_per_month','price']\n",
    "    x_title=['avg. monthly bookings','number of listings','number of bookings','price ($USD)']\n",
    "    title=['Monthly Bookings by neighbourhood','Number of listings','Average Monthly Bookings by listing'\n",
    "           ,'Average price by neighbourhood']\n",
    "    \n",
    "    for i in range(0,4):\n",
    "        if i==0 or i==2:\n",
    "            if i==0:\n",
    "                sp_data=listings.groupby(by='neighbourhood_cleansed').sum()[[col[i]]].sort_values(by=col[i], ascending=False)\n",
    "            else:\n",
    "                sp_data=listings.groupby(by='neighbourhood_cleansed').mean()[[col[i]]].sort_values(by=col[i], ascending=False)\n",
    "            \n",
    "            sp_data[col[i]]=sp_data[col[i]]*2\n",
    "            sp_data=sp_data.round({col[i]:1})\n",
    "        \n",
    "        elif i==1:\n",
    "            sp_data=listings.groupby(by='neighbourhood_cleansed').count()[[col[i]]].sort_values(by=col[i], ascending=False)\n",
    "            \n",
    "        elif i==3:\n",
    "            sp_data=listings[listings.price<=800].groupby(by='neighbourhood_cleansed').mean()[[col[i]]].sort_values(by=col[i]\n",
    "                    , ascending=False)\n",
    "        \n",
    "        plt.subplot(2,2,i+1)\n",
    "        sp_data[col[i]].plot(kind = 'barh' , figsize = (12,10),color=color[i])\n",
    "        plt.ylabel('')\n",
    "        plt.xlabel('avg. monthly bookings');\n",
    "        plt.title(title[i]);\n",
    "        plt.grid(True)\n",
    "\n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.25,\n",
    "                    wspace=0.55)\n",
    "\n",
    "    print(sp_data)\n",
    "    \n",
    "    return plt.show()\n",
    "\n",
    "demand_subplots(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the most demanded places are not the best for sightseeing as one had expected.\n",
    "\n",
    "On the one hand Dorchester and Allston, first and third most requested districts, are both very inexpensive. \n",
    "(Dorchester average price is almost half of downtown). Despite Dorchester is very far from \n",
    "Downtown, Red subway line operates throug it, offering a good transport option. \n",
    "Allston has the advantage that is not far from downtown offering a convenient option for tourist travelling by car.\n",
    "\n",
    "On the other hand, East Boston and South End (second and fourth respectively) are middle price neightbouhoods not so far from\n",
    "downtown and with a very broad offer of public transport."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
